{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.sys.path.append('../template_model')\n",
    "\n",
    "from reading_thiagos_templates import make_template, get_lexicalizations\n",
    "from collections import ChainMap, defaultdict, Counter\n",
    "import glob\n",
    "import csv\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from util import load_train_dev, Entry\n",
    "from more_itertools import flatten\n",
    "from template_based import abstract_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "td = load_train_dev()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_db = defaultdict(set)\n",
    "\n",
    "template_model_texts = []\n",
    "\n",
    "for e in [e for e in td if e.entity_map]:\n",
    "\n",
    "    for l in [l for l in e.lexes if l['comment'] == 'good' and l['template']]:\n",
    "        \n",
    "        ts = make_template(l['sorted_triples'], \n",
    "                           l['template'], \n",
    "                           e.r_entity_map)\n",
    "        \n",
    "        if ts is None:\n",
    "            break\n",
    "        \n",
    "        i_min = 0\n",
    "        i_max = 0\n",
    "        for t in ts:\n",
    "\n",
    "            template_db[(e.category, t.template_triples)].add(t)\n",
    "            \n",
    "            i_max += len(t.template_triples)\n",
    "            \n",
    "            triples = e.triples[i_min:i_max]\n",
    "            \n",
    "            text = t.fill(triples, lambda x, ctx: x, None)\n",
    "            \n",
    "            template_model_texts.append(text)\n",
    "            \n",
    "            i_min = i_max\n",
    "            \n",
    "            \n",
    "template_db = dict(template_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/templates/template_db/tdb', 'wb') as f:\n",
    "    pickle.dump(template_db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kenlm/ts_texts.txt', 'w', encoding='utf-8') as f:\n",
    "    for t in template_model_texts:\n",
    "        f.write(f'{t}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = Counter()\n",
    "triple_to_lex_1 = defaultdict(list)\n",
    "triple_to_lex_gt1 = defaultdict(list)\n",
    "\n",
    "for e in [e for e in td if e.entity_map]:\n",
    "\n",
    "    for l in [l for l in e.lexes if l['comment'] == 'good' and l['template']]:\n",
    "        \n",
    "        ts = make_template(l['sorted_triples'], \n",
    "                           l['template'], \n",
    "                           e.r_entity_map)\n",
    "        \n",
    "        for t in ts:\n",
    "\n",
    "            # para lidar com casos em que de templates mal definidos\n",
    "            if len(t.template_triples) > 0:\n",
    "\n",
    "                dados[(t, t.template_triples, e.category)] += 1\n",
    "\n",
    "            if len(e.triples) > 1:\n",
    "                    for triple in e.triples:\n",
    "\n",
    "                        triple_to_lex_gt1[triple].append(l['text'].lower())\n",
    "            else:\n",
    "                for triple in e.triples:\n",
    "\n",
    "                    triple_to_lex_1[triple].append(l['text'].lower())\n",
    "\n",
    "templates, templates_triples, categories = zip(*dados.keys())\n",
    "df = pd.DataFrame({'feature_template_cnt_in_category': list(dados.values()),\n",
    "                   'template': templates,\n",
    "                   'template_triples': templates_triples,\n",
    "                   'feature_template_category': categories})\n",
    "\n",
    "# para aquela estrutura e por categoria, quantos templates há\n",
    "g = df.groupby(['template_triples', 'feature_template_category'])['feature_template_cnt_in_category'].sum()\n",
    "g.name = 'template_triples_and_category_cnt'\n",
    "g = g.reset_index()\n",
    "\n",
    "df = pd.merge(df, g)\n",
    "df['feature_template_freq_in_category'] = df['feature_template_cnt_in_category'] / df['template_triples_and_category_cnt']\n",
    "del df['template_triples_and_category_cnt']\n",
    "    \n",
    "df.to_pickle('../data/templates/template_db/template_db')\n",
    "df.to_csv('../data/templates/template_db/template_db.csv', index=False)\n",
    "\n",
    "with open('../data/templates/template_db/triple_to_lex_1', 'wb') as f:\n",
    "    pickle.dump(triple_to_lex_1, f)\n",
    "    \n",
    "with open('../data/templates/template_db/triple_to_lex_gt1', 'wb') as f:\n",
    "    pickle.dump(triple_to_lex_gt1, f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lexicalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_db = defaultdict(lambda: Counter())\n",
    "pronoun_db = defaultdict(lambda: Counter())\n",
    "\n",
    "for entry in train_dev_entries:\n",
    "\n",
    "    for lexe in entry['lexes']:\n",
    "\n",
    "        if lexe['comment'] == 'good' and entry['entity_map']:\n",
    "\n",
    "            lexicals = get_lexicalizations(lexe['text'], lexe['template'], entry['entity_map'])\n",
    "\n",
    "            if lexicals:\n",
    "\n",
    "                for lex_key, lex_values in lexicals.items():\n",
    "                    \n",
    "                    for lex_value in lex_values:\n",
    "                        \n",
    "                        doc = nlp(lex_value)\n",
    "                        \n",
    "                        if len(doc) == 1 and doc[0].pos_ == 'PRON':\n",
    "                            \n",
    "                            pronoun_db[lex_key][lex_value] += 1\n",
    "                        else:\n",
    "                            name_db[lex_key][lex_value] += 1\n",
    "\n",
    "name_db = dict(name_db)\n",
    "pronoun_db = dict(pronoun_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/templates/lexicalization/thiago_name_db.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    \n",
    "    writer = csv.DictWriter(f, fieldnames=['lex_key', 'lex_value', 'n'])\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for lex_key, cc in name_db.items():\n",
    "    \n",
    "        for lex_value, n in cc.items():\n",
    "\n",
    "            writer.writerow(dict(lex_key=lex_key, lex_value=lex_value, n=n))\n",
    "            \n",
    "with open('../data/templates/lexicalization/thiago_pronoun_db.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    \n",
    "    writer = csv.DictWriter(f, fieldnames=['lex_key', 'lex_value', 'n'])\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for lex_key, cc in pronoun_db.items():\n",
    "    \n",
    "        for lex_value, n in cc.items():\n",
    "\n",
    "            writer.writerow(dict(lex_key=lex_key, lex_value=lex_value, n=n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/templates/lexicalization/thiago_name_db', 'wb') as f:\n",
    "    pickle.dump(name_db, f)\n",
    "\n",
    "with open('../data/templates/lexicalization/thiago_pronoun_db', 'wb') as f:\n",
    "    pickle.dump(pronoun_db, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/templates/lexicalization/thiago_lexicalization_db', 'wb') as f:\n",
    "    pickle.dump(lexicalization_db, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "c = re.compile(r'\\W')\n",
    "\n",
    "# https://www.kaggle.com/alvations/n-gram-language-model-with-nltk\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline, padded_everygrams\n",
    "\n",
    "tokenized_texts = []\n",
    "\n",
    "for e in train_dev_entries:\n",
    "    \n",
    "    for lexe in e['lexes']:\n",
    "        \n",
    "        if lexe['comment'] == 'good' and lexe['text']:\n",
    "            \n",
    "            tokenized = c.split(lexe['text'].lower())\n",
    "            \n",
    "            tokenized_texts.append(tokenized)\n",
    "            \n",
    "n = 2\n",
    "train_data, padded_sents = padded_everygram_pipeline(n, tokenized_texts)\n",
    "\n",
    "from nltk.lm import MLE\n",
    "\n",
    "model = MLE(n)\n",
    "model.fit(train_data, padded_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def score_sentence(s):\n",
    "    \n",
    "    ss = c.split(s.lower())\n",
    "    \n",
    "    scores = [model.score(w) for w in ss]\n",
    "    \n",
    "    non_zero_scores = [sc for sc in scores if sc != 0]\n",
    "    \n",
    "    return reduce(lambda x, y: x*y, non_zero_scores, 1)\n",
    "\n",
    "def outro_score(s):\n",
    "    \n",
    "    ss = padded_everygrams(n, c.split(s.lower()))\n",
    "    \n",
    "    return model.entropy(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/templates/template_db/thiago_template_db', 'rb') as f:\n",
    "    template_db = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <s, p, o> + <s, p', o'> = <s, [<p, o>, <p', o'>]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from template_based import *\n",
    "\n",
    "RE_REMOVE_FINAL_DOT = re.compile(r'\\.$')\n",
    "# assumes the sentence is in active voice\n",
    "RE_REMOVE_AGENT_1 = re.compile(r'^.*?{AGENT-1}')\n",
    "\n",
    "def make_text(t1, t2):\n",
    "    \n",
    "    t1_ = RE_REMOVE_FINAL_DOT.sub('', t1)\n",
    "    \n",
    "    t2_ = RE_REMOVE_AGENT_1.sub('', t2).replace('{PATIENT-1}', '{PATIENT-2}')\n",
    "    \n",
    "    return '{} and {}'.format(t1_, t2_)\n",
    "\n",
    "def make_structure(h1, h2):\n",
    "    \n",
    "    o1 = Slot('PATIENT-1', [])\n",
    "    p1 = Predicate(h1.predicates[0].value, [o1])\n",
    "    o2 = Slot('PATIENT-2', [])\n",
    "    p2 = Predicate(h2.predicates[0].value, [o2])\n",
    "    \n",
    "    s = Slot('AGENT-1', [p1, p2])\n",
    "    \n",
    "    return Structure(s)\n",
    "\n",
    "def make_new_template(t1, t2):\n",
    "    \n",
    "    template_text = make_text(t1.template_text, t2.template_text)\n",
    "    structure = make_structure(t1.structure.head, t2.structure.head)\n",
    "    \n",
    "    return Template(structure, template_text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "templates_w_1_size = []\n",
    "template_enhanced_db = defaultdict(lambda: defaultdict(Counter), template_db)\n",
    "\n",
    "for s, cc in template_db.items():\n",
    "    if len(s) == 1:\n",
    "        for tc in cc.values():\n",
    "            templates_w_1_size.extend(tc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 19s, sys: 54.9 s, total: 8min 14s\n",
      "Wall time: 8min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#probably passive voice\n",
    "w_error = []\n",
    "\n",
    "for t1, t2 in combinations(templates_w_1_size, 2):\n",
    "\n",
    "    try:\n",
    "        t12 = make_new_template(t1, t2)\n",
    "        template_enhanced_db[t12.structure][t1.structure.head.value][t12] +=1\n",
    "    except:\n",
    "        w_error.append((t1, t2))\n",
    "\n",
    "    try:\n",
    "        t21 = make_new_template(t2, t1)\n",
    "        template_enhanced_db[t21.structure][t2.structure.head.value][t21] +=1\n",
    "    except:\n",
    "        w_error.append((t2, t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/templates/template_db/thiago_template_db_rule_1', 'wb') as f:\n",
    "    pickle.dump(dict(template_enhanced_db), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58642"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(template_enhanced_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing spacy string dependency tree parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure: [AGENT-1, \n",
       "\n",
       "\t<tenant, [\n",
       "\t\t[BRIDGE-1, \n",
       "\n",
       "\t\t\t<foundationPlace, [PATIENT-1]>]]>]\n",
       "Text: {BRIDGE-1} which was founded in {PATIENT-1} is the tenant of {AGENT-1}."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = list(template_db.values())[400].most_common()[0][0]\n",
    "\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"1975\" height=\"487.0\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">{BRIDGE-1}</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">which</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">founded</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">{PATIENT-1}</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">tenant</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">{AGENT-1}</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 1100.0,2.0 1100.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubjpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,354.0 L237,342.0 253,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">auxpass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M570.0,354.0 L578.0,342.0 562.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,264.5 735.0,264.5 735.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M735.0,354.0 L743.0,342.0 727.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1440.0,354.0 L1448.0,342.0 1432.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-8\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,264.5 1610.0,264.5 1610.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-8\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1610.0,354.0 L1618.0,342.0 1602.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-9\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-9\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1785.0,354.0 L1793.0,342.0 1777.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "# weird, spacy doesn't respect special cases if they appear in the end of the string, preceeded by a dot...\n",
    "import re\n",
    "c = re.compile(r'\\.$')\n",
    "\n",
    "for s in ['{AGENT-1}', '{PATIENT-1}', '{BRIDGE-1}']:\n",
    "    special_case = [{'ORTH': s, 'TAG': 'NN'}]\n",
    "    nlp.tokenizer.add_special_case(s, special_case)\n",
    "\n",
    "doc = nlp(c.sub('', t.template_text))\n",
    "\n",
    "displacy.render(doc, jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a subset containing only the entries with template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../evaluation/test.pkl', 'rb') as f:\n",
    "    test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_w_template = []\n",
    "\n",
    "for i, entry in enumerate(test):\n",
    "    \n",
    "    try:\n",
    "        s = Structure.from_triples(entry['triples'])\n",
    "\n",
    "        if s in template_db:\n",
    "            entries_w_template.append(i)\n",
    "    except MoreThanOneRootException:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../evaluation/subsets/with-template.txt', 'w', encoding='utf-8') as f:\n",
    "    \n",
    "    f.writelines(f'{i}\\n' for i in entries_w_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testando a ideia de calcular uma prioridade de um template em função das suas partes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure: (Triple(subject='slot0', predicate='deathPlace', object='slot1'), Triple(subject='slot1', predicate='isPartOf', object='slot2'))\n",
       "Text: {slot0} died in {slot1} (part of {slot2}) ."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = templates[4950]\n",
    "t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## agora vamos ver quantas vezes deathPlace é verbalizado com 'died in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = [t for t in templates if 'deathPlace' in [tr.predicate for tr in t.template_triples] and ' died in ' in t.template_text]\n",
    "len(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "593"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdish = [t for t in templates if 'dishVariation' in [tr.predicate for tr in t.template_triples]]\n",
    "\n",
    "len(tdish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttdish = [t for t in tdish if 'can be varied by using' in t.template_text]\n",
    "\n",
    "len(ttdish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
